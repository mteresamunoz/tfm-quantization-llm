2025-10-07 15:26:23.730 | INFO     | llmcompressor.metrics.logger:_create_default_logger:357 - Logging all LLM Compressor modifier-level logs to sparse_logs/07-10-2025_15.26.23.log
2025-10-07 15:26:23.731 | DEBUG    | llmcompressor.core.lifecycle:initialize:92 - Initializing compression lifecycle
2025-10-07 15:26:23.732 | INFO     | llmcompressor.recipe.recipe:create_instance:140 - Loading recipe from file /gaueko1/users/mmartin/ptq_exp/yaml/gptq_w4a16_recipe.yaml
2025-10-07 15:26:23.927 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:26:23.927 | INFO     | llmcompressor.core.lifecycle:initialize:110 - Compression lifecycle initialized for 1 modifiers
2025-10-07 15:26:23.927 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `GPTQModifier`
2025-10-07 15:26:28.129 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-07 15:26:28.130 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2025-10-07 15:26:28.130 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-07 15:26:28.131 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-07 15:26:28.132 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds: torch.Tensor = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2025-10-07 15:26:28.133 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-07 15:26:28.133 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-07 15:26:28.134 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache(config=self.config)
    return (past_key_values,)
2025-10-07 15:26:28.134 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-07 15:26:28.135 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-07 15:26:28.136 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position: torch.Tensor = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2025-10-07 15:26:28.136 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-07 15:26:28.137 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-07 15:26:28.137 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2025-10-07 15:26:28.138 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-07 15:26:28.139 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-07 15:26:28.139 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids):
    return create_causal_mask(config=self.config, input_embeds=inputs_embeds, attention_mask=attention_mask, cache_position=cache_position, past_key_values=past_key_values, position_ids=position_ids)
    return ()
2025-10-07 15:26:28.139 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-07 15:26:28.143 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-07 15:26:28.143 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2025-10-07 15:26:28.144 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-07 15:26:28.236 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2025-10-07 15:26:28.248 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e737050>
2025-10-07 15:26:28.248 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c6a50>
2025-10-07 15:26:28.249 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dd790>
2025-10-07 15:26:28.250 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dd9d0>
2025-10-07 15:26:28.251 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7ddb90>
2025-10-07 15:26:28.251 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7ddcd0>
2025-10-07 15:26:28.253 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7ddf50>
2025-10-07 15:26:28.254 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c5b50>
2025-10-07 15:26:28.254 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de090>
2025-10-07 15:26:28.254 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de2d0>
2025-10-07 15:26:28.255 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de310>
2025-10-07 15:26:28.255 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de3d0>
2025-10-07 15:26:28.255 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de290>
2025-10-07 15:26:28.255 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de590>
2025-10-07 15:26:28.255 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de890>
2025-10-07 15:26:28.256 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dea50>
2025-10-07 15:26:28.257 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7deb10>
2025-10-07 15:26:28.258 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e746c10>
2025-10-07 15:26:28.259 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dead0>
2025-10-07 15:26:28.260 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dea90>
2025-10-07 15:26:28.260 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e756ed0>
2025-10-07 15:26:28.261 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c6150>
2025-10-07 15:26:28.262 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7df110>
2025-10-07 15:26:28.263 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7df250>
2025-10-07 15:26:28.264 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7df410>
2025-10-07 15:26:28.264 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7df590>
2025-10-07 15:26:28.265 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7df510>
2025-10-07 15:26:28.265 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7df650>
2025-10-07 15:26:28.266 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dfa90>
2025-10-07 15:26:28.267 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dfa10>
2025-10-07 15:26:28.267 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dfd90>
2025-10-07 15:26:28.267 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7dff50>
2025-10-07 15:26:28.267 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0290>
2025-10-07 15:26:28.267 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0450>
2025-10-07 15:26:28.267 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f05d0>
2025-10-07 15:26:28.268 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0790>
2025-10-07 15:26:28.269 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e71fb90>
2025-10-07 15:26:28.270 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0a10>
2025-10-07 15:26:28.271 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0b90>
2025-10-07 15:26:28.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f06d0>
2025-10-07 15:26:28.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0ed0>
2025-10-07 15:26:28.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1090>
2025-10-07 15:26:28.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0710>
2025-10-07 15:26:28.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f12d0>
2025-10-07 15:26:28.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f13d0>
2025-10-07 15:26:28.272 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1450>
2025-10-07 15:26:28.273 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1510>
2025-10-07 15:26:28.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f17d0>
2025-10-07 15:26:28.275 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f18d0>
2025-10-07 15:26:28.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f19d0>
2025-10-07 15:26:28.276 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1650>
2025-10-07 15:26:28.277 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1d50>
2025-10-07 15:26:28.278 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1f10>
2025-10-07 15:26:28.279 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdeec10e1d0>
2025-10-07 15:26:28.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1f90>
2025-10-07 15:26:28.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f22d0>
2025-10-07 15:26:28.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2250>
2025-10-07 15:26:28.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2710>
2025-10-07 15:26:28.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2810>
2025-10-07 15:26:28.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab0153e90>
2025-10-07 15:26:28.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2b90>
2025-10-07 15:26:28.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2c90>
2025-10-07 15:26:28.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2dd0>
2025-10-07 15:26:28.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2fd0>
2025-10-07 15:26:28.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f3110>
2025-10-07 15:26:28.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f3090>
2025-10-07 15:26:28.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e71ec10>
2025-10-07 15:26:28.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f1b50>
2025-10-07 15:26:28.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fde8e146150>
2025-10-07 15:26:28.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e716c50>
2025-10-07 15:26:28.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2d50>
2025-10-07 15:26:28.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f3450>
2025-10-07 15:26:28.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f3b10>
2025-10-07 15:26:28.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e732a90>
2025-10-07 15:26:28.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdb0c1ae110>
2025-10-07 15:26:28.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f3f10>
2025-10-07 15:26:28.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fc150>
2025-10-07 15:26:28.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fc350>
2025-10-07 15:26:28.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fc0d0>
2025-10-07 15:26:28.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fc6d0>
2025-10-07 15:26:28.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fc8d0>
2025-10-07 15:26:28.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fc790>
2025-10-07 15:26:28.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e745d10>
2025-10-07 15:26:28.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e71dd50>
2025-10-07 15:26:28.297 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fcd50>
2025-10-07 15:26:28.297 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fce10>
2025-10-07 15:26:28.298 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e737690>
2025-10-07 15:26:28.298 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fd210>
2025-10-07 15:26:28.299 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fd250>
2025-10-07 15:26:28.300 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e735150>
2025-10-07 15:26:28.301 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e745610>
2025-10-07 15:26:28.301 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fd290>
2025-10-07 15:26:28.301 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fd850>
2025-10-07 15:26:28.301 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fda10>
2025-10-07 15:26:28.301 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fda90>
2025-10-07 15:26:28.301 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fd990>
2025-10-07 15:26:28.301 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fdd90>
2025-10-07 15:26:28.302 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fdf90>
2025-10-07 15:26:28.303 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fde50>
2025-10-07 15:26:28.303 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fe150>
2025-10-07 15:26:28.305 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fe1d0>
2025-10-07 15:26:28.305 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fe4d0>
2025-10-07 15:26:28.305 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fe590>
2025-10-07 15:26:28.305 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e756490>
2025-10-07 15:26:28.305 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fe790>
2025-10-07 15:26:28.306 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fe6d0>
2025-10-07 15:26:28.306 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e756410>
2025-10-07 15:26:28.306 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fe850>
2025-10-07 15:26:28.306 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5feb10>
2025-10-07 15:26:28.307 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e755ad0>
2025-10-07 15:26:28.308 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5febd0>
2025-10-07 15:26:28.309 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7567d0>
2025-10-07 15:26:28.309 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5ff250>
2025-10-07 15:26:28.309 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab0189910>
2025-10-07 15:26:28.309 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e715510>
2025-10-07 15:26:28.309 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5ff3d0>
2025-10-07 15:26:28.309 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7161d0>
2025-10-07 15:26:28.309 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5ff150>
2025-10-07 15:26:28.311 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7def50>
2025-10-07 15:26:28.312 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5ffa90>
2025-10-07 15:26:28.313 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdb0c186250>
2025-10-07 15:26:28.313 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0390>
2025-10-07 15:26:28.314 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c6310>
2025-10-07 15:26:28.315 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e736290>
2025-10-07 15:26:28.315 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdeedd02d90>
2025-10-07 15:26:28.316 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2ad0>
2025-10-07 15:26:28.317 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e6082d0>
2025-10-07 15:26:28.317 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e6083d0>
2025-10-07 15:26:28.317 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e608550>
2025-10-07 15:26:28.317 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e608690>
2025-10-07 15:26:28.317 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f0810>
2025-10-07 15:26:28.317 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e6087d0>
2025-10-07 15:26:28.317 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e608a10>
2025-10-07 15:26:28.319 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e608b50>
2025-10-07 15:26:28.320 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e608c90>
2025-10-07 15:26:28.321 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5ffd50>
2025-10-07 15:26:28.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e608f50>
2025-10-07 15:26:28.322 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e609050>
2025-10-07 15:26:28.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fde8e144e10>
2025-10-07 15:26:28.323 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdeec10e290>
2025-10-07 15:26:28.325 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e609210>
2025-10-07 15:26:28.326 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e6093d0>
2025-10-07 15:26:28.326 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de110>
2025-10-07 15:26:28.326 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e6092d0>
2025-10-07 15:26:28.326 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e6097d0>
2025-10-07 15:26:28.327 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e6099d0>
2025-10-07 15:26:28.327 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e609bd0>
2025-10-07 15:26:28.327 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e608a90>
2025-10-07 15:26:28.327 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e609d90>
2025-10-07 15:26:28.328 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e609f50>
2025-10-07 15:26:28.329 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab0151010>
2025-10-07 15:26:28.330 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60a190>
2025-10-07 15:26:28.331 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e609c10>
2025-10-07 15:26:28.331 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60a250>
2025-10-07 15:26:28.331 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60a550>
2025-10-07 15:26:28.331 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c6550>
2025-10-07 15:26:28.331 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7df5d0>
2025-10-07 15:26:28.331 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f3050>
2025-10-07 15:26:28.332 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60a790>
2025-10-07 15:26:28.333 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60aad0>
2025-10-07 15:26:28.334 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60abd0>
2025-10-07 15:26:28.335 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60a010>
2025-10-07 15:26:28.336 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60ae10>
2025-10-07 15:26:28.337 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60afd0>
2025-10-07 15:26:28.337 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60b0d0>
2025-10-07 15:26:28.338 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c6250>
2025-10-07 15:26:28.338 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60b390>
2025-10-07 15:26:28.340 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60b410>
2025-10-07 15:26:28.340 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f2090>
2025-10-07 15:26:28.341 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60b690>
2025-10-07 15:26:28.342 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60b710>
2025-10-07 15:26:28.343 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60b850>
2025-10-07 15:26:28.343 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60b950>
2025-10-07 15:26:28.344 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60ba50>
2025-10-07 15:26:28.345 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdeec106d50>
2025-10-07 15:26:28.345 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de610>
2025-10-07 15:26:28.346 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdeec10f790>
2025-10-07 15:26:28.347 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7f3dd0>
2025-10-07 15:26:28.347 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60bf10>
2025-10-07 15:26:28.348 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60be10>
2025-10-07 15:26:28.349 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e60bfd0>
2025-10-07 15:26:28.350 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e714e10>
2025-10-07 15:26:28.350 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61c2d0>
2025-10-07 15:26:28.351 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61c4d0>
2025-10-07 15:26:28.351 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61c450>
2025-10-07 15:26:28.352 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61c6d0>
2025-10-07 15:26:28.353 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c6510>
2025-10-07 15:26:28.354 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e71fe90>
2025-10-07 15:26:28.355 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fca50>
2025-10-07 15:26:28.355 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61cb90>
2025-10-07 15:26:28.355 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdb0c119e50>
2025-10-07 15:26:28.355 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61cc50>
2025-10-07 15:26:28.355 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5fcf10>
2025-10-07 15:26:28.355 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61ce10>
2025-10-07 15:26:28.355 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdeedce7f50>
2025-10-07 15:26:28.357 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e754650>
2025-10-07 15:26:28.358 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61d350>
2025-10-07 15:26:28.359 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61d490>
2025-10-07 15:26:28.359 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61d390>
2025-10-07 15:26:28.360 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61d690>
2025-10-07 15:26:28.360 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e746510>
2025-10-07 15:26:28.360 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61d890>
2025-10-07 15:26:28.360 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61d8d0>
2025-10-07 15:26:28.360 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61dad0>
2025-10-07 15:26:28.360 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c6490>
2025-10-07 15:26:28.361 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61d990>
2025-10-07 15:26:28.362 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdab01c7c90>
2025-10-07 15:26:28.364 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61dc90>
2025-10-07 15:26:28.364 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61dfd0>
2025-10-07 15:26:28.364 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e7de150>
2025-10-07 15:26:28.364 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61df90>
2025-10-07 15:26:28.364 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61e350>
2025-10-07 15:26:28.364 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61e650>
2025-10-07 15:26:28.365 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61e610>
2025-10-07 15:26:28.365 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61e750>
2025-10-07 15:26:28.366 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61e790>
2025-10-07 15:26:28.367 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61e990>
2025-10-07 15:26:28.368 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61de90>
2025-10-07 15:26:28.369 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61ec10>
2025-10-07 15:26:28.369 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61eb10>
2025-10-07 15:26:28.370 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61ed50>
2025-10-07 15:26:28.370 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61eed0>
2025-10-07 15:26:28.372 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e5ffb90>
2025-10-07 15:26:28.372 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x7fdf6e61f190>
2025-10-07 15:26:28.373 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:26:36.689 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:26:36.690 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.q_proj using 512 samples
2025-10-07 15:26:42.547 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.86s
2025-10-07 15:26:42.547 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 64.58
2025-10-07 15:26:42.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.17% | total memory: 85 GB
2025-10-07 15:26:42.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:42.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 75.93% | total memory: 85 GB
2025-10-07 15:26:42.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:26:42.551 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:26:42.551 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:42.552 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:42.553 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:42.553 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:26:42.554 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.k_proj using 512 samples
2025-10-07 15:26:44.049 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:26:44.050 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 37.04
2025-10-07 15:26:44.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.17% | total memory: 85 GB
2025-10-07 15:26:44.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:44.052 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 75.93% | total memory: 85 GB
2025-10-07 15:26:44.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:26:44.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:26:44.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:44.054 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:44.055 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:44.055 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:26:44.056 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.v_proj using 512 samples
2025-10-07 15:26:45.576 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:26:45.577 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.46
2025-10-07 15:26:45.578 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.17% | total memory: 85 GB
2025-10-07 15:26:45.578 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:45.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 75.93% | total memory: 85 GB
2025-10-07 15:26:45.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:26:45.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:26:45.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:45.581 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:45.582 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:45.582 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:26:45.583 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.self_attn.o_proj using 512 samples
2025-10-07 15:26:47.142 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:26:47.142 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.06
2025-10-07 15:26:47.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.17% | total memory: 85 GB
2025-10-07 15:26:47.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:47.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:26:47.145 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:26:47.145 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:26:47.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:47.147 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:47.147 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:47.148 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:26:47.149 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.mlp.gate_proj using 512 samples
2025-10-07 15:26:48.811 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.66s
2025-10-07 15:26:48.812 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 54.55
2025-10-07 15:26:48.813 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.17% | total memory: 85 GB
2025-10-07 15:26:48.813 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:48.814 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:26:48.814 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:26:48.814 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:26:48.814 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:48.814 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:48.814 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:48.814 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:26:48.814 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.mlp.up_proj using 512 samples
2025-10-07 15:26:50.478 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.66s
2025-10-07 15:26:50.478 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 44.22
2025-10-07 15:26:50.479 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.17% | total memory: 85 GB
2025-10-07 15:26:50.480 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:50.480 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:26:50.481 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:26:50.482 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:26:50.482 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:50.483 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:50.483 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:50.484 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:26:50.485 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.0.mlp.down_proj using 512 samples
2025-10-07 15:26:56.456 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.97s
2025-10-07 15:26:56.459 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.18
2025-10-07 15:26:56.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 9.08% | total memory: 85 GB
2025-10-07 15:26:56.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:56.461 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:26:56.461 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:26:56.461 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:26:56.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:56.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:56.463 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:26:56.463 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:26:56.464 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:27:03.650 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:27:03.650 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.q_proj using 512 samples
2025-10-07 15:27:05.234 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:27:05.235 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 66.30
2025-10-07 15:27:05.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:27:05.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:05.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:27:05.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:05.237 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:05.237 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:05.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:05.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:05.239 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:27:05.240 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.k_proj using 512 samples
2025-10-07 15:27:06.708 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:27:06.708 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 37.74
2025-10-07 15:27:06.708 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:27:06.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:06.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:27:06.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:06.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:06.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:06.712 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:06.713 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:06.713 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:27:06.714 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.v_proj using 512 samples
2025-10-07 15:27:08.210 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:27:08.210 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.82
2025-10-07 15:27:08.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:27:08.212 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:08.212 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:27:08.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:08.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:08.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:08.215 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:08.215 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:08.216 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:27:08.217 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.self_attn.o_proj using 512 samples
2025-10-07 15:27:09.713 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:27:09.713 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.11
2025-10-07 15:27:09.714 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:27:09.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:09.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:27:09.716 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:09.716 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:09.717 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:09.719 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:09.719 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:09.719 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:27:09.720 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.mlp.gate_proj using 512 samples
2025-10-07 15:27:11.297 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:27:11.297 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 122.55
2025-10-07 15:27:11.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:27:11.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:11.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:27:11.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:11.300 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:11.300 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:11.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:11.302 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:11.302 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:11.303 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.mlp.up_proj using 512 samples
2025-10-07 15:27:12.884 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:27:12.885 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 103.90
2025-10-07 15:27:12.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:27:12.886 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:12.886 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 89.24% | total memory: 85 GB
2025-10-07 15:27:12.886 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:12.887 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:12.887 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:12.888 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:12.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:12.889 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:12.889 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.1.mlp.down_proj using 512 samples
2025-10-07 15:27:19.067 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 6.18s
2025-10-07 15:27:19.068 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 833.66
2025-10-07 15:27:19.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:27:19.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:19.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.39% | total memory: 85 GB
2025-10-07 15:27:19.070 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:19.070 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:19.070 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:19.072 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:19.073 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:27:25.638 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:27:25.638 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.q_proj using 512 samples
2025-10-07 15:27:27.176 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.54s
2025-10-07 15:27:27.176 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 431.02
2025-10-07 15:27:27.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:27.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:27.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 83.68% | total memory: 85 GB
2025-10-07 15:27:27.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:27.178 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:27.179 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:27.179 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:27.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:27.180 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:27:27.181 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.k_proj using 512 samples
2025-10-07 15:27:28.670 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:27:28.670 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 264.25
2025-10-07 15:27:28.670 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:28.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:28.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 83.68% | total memory: 85 GB
2025-10-07 15:27:28.672 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:28.672 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:28.673 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:28.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:28.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:28.675 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:27:28.676 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.v_proj using 512 samples
2025-10-07 15:27:30.157 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:27:30.158 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 14.35
2025-10-07 15:27:30.158 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:30.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:30.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 83.68% | total memory: 85 GB
2025-10-07 15:27:30.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:30.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:30.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:30.161 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:30.162 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:30.162 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:27:30.163 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.self_attn.o_proj using 512 samples
2025-10-07 15:27:31.686 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:27:31.687 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.05
2025-10-07 15:27:31.687 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:31.687 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:31.688 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 83.68% | total memory: 85 GB
2025-10-07 15:27:31.689 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:31.689 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:31.690 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:31.690 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:31.691 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:31.692 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:27:31.692 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.mlp.gate_proj using 512 samples
2025-10-07 15:27:33.265 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:27:33.266 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 269.93
2025-10-07 15:27:33.266 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:33.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:33.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 83.68% | total memory: 85 GB
2025-10-07 15:27:33.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:33.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 95.51% | total memory: 85 GB
2025-10-07 15:27:33.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:33.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:33.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:33.271 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:33.272 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.mlp.up_proj using 512 samples
2025-10-07 15:27:34.891 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.62s
2025-10-07 15:27:34.892 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 214.70
2025-10-07 15:27:34.893 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:34.893 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:34.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 48.33% | total memory: 85 GB
2025-10-07 15:27:34.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:34.895 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 97.84% | total memory: 85 GB
2025-10-07 15:27:34.895 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:34.896 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:34.896 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:34.897 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:34.897 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.2.mlp.down_proj using 512 samples
2025-10-07 15:27:40.692 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.79s
2025-10-07 15:27:40.694 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.95
2025-10-07 15:27:40.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:27:40.695 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:40.695 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:27:40.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:40.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 99.54% | total memory: 85 GB
2025-10-07 15:27:40.697 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:40.697 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:40.698 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:40.699 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:40.699 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:27:47.249 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:27:47.250 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.q_proj using 512 samples
2025-10-07 15:27:48.759 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:27:48.760 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 490.89
2025-10-07 15:27:48.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:48.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:48.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:27:48.762 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:48.762 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 99.51% | total memory: 85 GB
2025-10-07 15:27:48.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:48.764 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:48.764 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:48.765 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:27:48.765 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.k_proj using 512 samples
2025-10-07 15:27:50.268 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:27:50.269 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 270.97
2025-10-07 15:27:50.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:50.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:50.271 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:27:50.271 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:50.272 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:50.272 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:50.273 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:50.273 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:50.274 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:27:50.274 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.v_proj using 512 samples
2025-10-07 15:27:51.799 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:27:51.800 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 25.34
2025-10-07 15:27:51.801 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:51.801 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:51.802 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:27:51.802 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:51.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:51.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:51.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:51.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:51.805 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:27:51.805 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.self_attn.o_proj using 512 samples
2025-10-07 15:27:53.312 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:27:53.313 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.42
2025-10-07 15:27:53.313 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:53.314 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:53.314 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:27:53.314 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:53.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:53.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:53.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:53.317 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:53.317 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:27:53.317 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.mlp.gate_proj using 512 samples
2025-10-07 15:27:54.931 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.61s
2025-10-07 15:27:54.932 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 450.09
2025-10-07 15:27:54.933 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:54.933 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:54.933 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:27:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:54.935 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:54.936 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:54.936 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:54.937 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.mlp.up_proj using 512 samples
2025-10-07 15:27:56.515 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:27:56.515 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 312.46
2025-10-07 15:27:56.516 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:27:56.516 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:56.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:27:56.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:27:56.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:56.518 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:56.519 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:56.519 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:27:56.520 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:27:56.520 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.3.mlp.down_proj using 512 samples
2025-10-07 15:28:02.266 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.75s
2025-10-07 15:28:02.267 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.08
2025-10-07 15:28:02.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:28:02.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:02.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:02.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:02.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:02.271 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:02.271 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:02.272 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:02.272 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:02.273 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:28:08.746 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:28:08.746 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.q_proj using 512 samples
2025-10-07 15:28:10.253 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:28:10.253 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 439.58
2025-10-07 15:28:10.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:10.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:10.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:10.255 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:10.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:10.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:10.257 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:10.257 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:10.258 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:28:10.259 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.k_proj using 512 samples
2025-10-07 15:28:11.728 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:28:11.729 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 252.58
2025-10-07 15:28:11.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:11.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:11.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:11.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:11.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:11.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:11.732 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:11.732 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:11.732 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:28:11.733 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.v_proj using 512 samples
2025-10-07 15:28:13.204 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:28:13.205 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 25.70
2025-10-07 15:28:13.205 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:13.206 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:13.206 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:13.206 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:13.206 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:13.207 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:13.207 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:13.208 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:13.209 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:28:13.209 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.self_attn.o_proj using 512 samples
2025-10-07 15:28:14.728 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:28:14.728 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.30
2025-10-07 15:28:14.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:14.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:14.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:14.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:14.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.85% | total memory: 85 GB
2025-10-07 15:28:14.732 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:14.732 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:14.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:14.733 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:28:14.734 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.mlp.gate_proj using 512 samples
2025-10-07 15:28:16.318 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:28:16.318 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 615.10
2025-10-07 15:28:16.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:16.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:16.326 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:16.326 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:16.327 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 2.08% | total memory: 85 GB
2025-10-07 15:28:16.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:16.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:16.329 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:16.329 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:16.330 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.mlp.up_proj using 512 samples
2025-10-07 15:28:17.926 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.60s
2025-10-07 15:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 378.37
2025-10-07 15:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:17.928 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:17.928 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:17.929 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:17.930 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 36.54% | total memory: 85 GB
2025-10-07 15:28:17.930 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:17.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:17.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:17.932 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:17.933 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.4.mlp.down_proj using 512 samples
2025-10-07 15:28:23.619 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.69s
2025-10-07 15:28:23.620 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.22
2025-10-07 15:28:23.620 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:28:23.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:23.622 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:23.622 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:23.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 36.54% | total memory: 85 GB
2025-10-07 15:28:23.624 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:23.624 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:23.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:23.625 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:23.626 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:28:30.145 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:28:30.145 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.q_proj using 512 samples
2025-10-07 15:28:31.643 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:28:31.643 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 657.83
2025-10-07 15:28:31.644 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:31.645 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:31.645 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:31.646 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:31.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 69.69% | total memory: 85 GB
2025-10-07 15:28:31.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:31.648 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:31.648 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:31.649 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:28:31.650 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.k_proj using 512 samples
2025-10-07 15:28:33.119 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:28:33.120 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 402.89
2025-10-07 15:28:33.120 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:33.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:33.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:33.122 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:33.122 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 72.60% | total memory: 85 GB
2025-10-07 15:28:33.123 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:33.124 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:33.124 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:33.125 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:28:33.125 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.v_proj using 512 samples
2025-10-07 15:28:34.608 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:28:34.608 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 26.70
2025-10-07 15:28:34.608 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:34.609 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:34.609 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:34.610 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:34.610 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.51% | total memory: 85 GB
2025-10-07 15:28:34.610 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:34.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:34.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:34.612 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:28:34.613 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.self_attn.o_proj using 512 samples
2025-10-07 15:28:36.143 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:28:36.144 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.32
2025-10-07 15:28:36.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:36.145 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:36.145 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:36.145 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:36.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.51% | total memory: 85 GB
2025-10-07 15:28:36.147 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:36.147 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:36.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:36.148 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:28:36.149 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.mlp.gate_proj using 512 samples
2025-10-07 15:28:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:28:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 763.15
2025-10-07 15:28:37.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:37.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:37.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:37.712 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:37.712 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.51% | total memory: 85 GB
2025-10-07 15:28:37.713 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:37.713 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:37.714 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:37.715 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:37.715 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.mlp.up_proj using 512 samples
2025-10-07 15:28:39.255 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.54s
2025-10-07 15:28:39.256 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 473.67
2025-10-07 15:28:39.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:39.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:39.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:39.257 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:39.258 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.51% | total memory: 85 GB
2025-10-07 15:28:39.258 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:39.259 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:39.260 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:39.260 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:39.261 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.5.mlp.down_proj using 512 samples
2025-10-07 15:28:45.014 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.75s
2025-10-07 15:28:45.015 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6.34
2025-10-07 15:28:45.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:28:45.017 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:45.017 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:45.018 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:45.018 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:28:45.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:45.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:45.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:45.020 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:45.021 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:28:51.566 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:28:51.566 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.q_proj using 512 samples
2025-10-07 15:28:53.049 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:28:53.050 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 637.78
2025-10-07 15:28:53.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:53.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:53.052 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:53.052 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:53.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:28:53.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:53.054 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:53.054 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:53.055 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:28:53.055 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.k_proj using 512 samples
2025-10-07 15:28:54.536 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:28:54.537 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 352.68
2025-10-07 15:28:54.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:54.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:54.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:54.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:54.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:28:54.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:54.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:54.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:54.540 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:28:54.540 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.v_proj using 512 samples
2025-10-07 15:28:56.044 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:28:56.044 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 31.28
2025-10-07 15:28:56.045 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:56.045 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:56.046 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:56.047 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:56.047 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:28:56.048 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:56.049 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:56.049 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:56.050 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:28:56.051 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.self_attn.o_proj using 512 samples
2025-10-07 15:28:57.563 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:28:57.563 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.57
2025-10-07 15:28:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:57.565 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:57.565 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:57.566 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:28:57.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:57.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:57.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:57.568 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:28:57.568 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.mlp.gate_proj using 512 samples
2025-10-07 15:28:59.109 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.54s
2025-10-07 15:28:59.109 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 873.49
2025-10-07 15:28:59.109 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:28:59.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:59.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:28:59.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:28:59.111 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:28:59.111 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:59.112 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:59.112 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:28:59.113 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:28:59.113 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.mlp.up_proj using 512 samples
2025-10-07 15:29:00.667 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:29:00.668 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 534.66
2025-10-07 15:29:00.668 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:00.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:00.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:00.670 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:00.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:00.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:00.672 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:00.672 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:00.673 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:00.674 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.6.mlp.down_proj using 512 samples
2025-10-07 15:29:06.468 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.79s
2025-10-07 15:29:06.469 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8.00
2025-10-07 15:29:06.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:29:06.470 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:06.470 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:06.470 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:06.471 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:06.472 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:06.472 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:06.473 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:06.474 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:06.474 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:29:13.016 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:29:13.016 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.q_proj using 512 samples
2025-10-07 15:29:14.504 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:29:14.504 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 640.17
2025-10-07 15:29:14.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:14.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:14.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:14.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:14.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:14.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:14.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:14.509 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:14.509 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:29:14.510 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.k_proj using 512 samples
2025-10-07 15:29:16.018 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:29:16.018 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 379.58
2025-10-07 15:29:16.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:16.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:16.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:16.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:16.021 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:16.022 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:16.022 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:16.023 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:16.023 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:29:16.024 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.v_proj using 512 samples
2025-10-07 15:29:17.539 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:29:17.540 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 33.30
2025-10-07 15:29:17.540 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:17.540 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:17.541 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:17.541 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:17.542 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:17.542 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:17.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:17.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:17.544 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:29:17.544 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.self_attn.o_proj using 512 samples
2025-10-07 15:29:19.054 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:29:19.054 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.41
2025-10-07 15:29:19.055 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:19.055 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:19.056 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:19.056 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:19.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:19.058 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:19.058 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:19.059 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:19.060 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:29:19.060 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.mlp.gate_proj using 512 samples
2025-10-07 15:29:20.621 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:29:20.621 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 903.67
2025-10-07 15:29:20.622 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:20.622 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:20.622 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:20.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:20.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:20.624 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:20.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:20.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:20.626 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:20.627 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.mlp.up_proj using 512 samples
2025-10-07 15:29:22.184 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:29:22.185 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 594.55
2025-10-07 15:29:22.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:22.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:22.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:22.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:22.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:22.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:22.186 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:22.186 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:22.187 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:22.188 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.7.mlp.down_proj using 512 samples
2025-10-07 15:29:28.017 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.83s
2025-10-07 15:29:28.019 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9.60
2025-10-07 15:29:28.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:28.020 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:28.021 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:29:34.563 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:29:34.563 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.q_proj using 512 samples
2025-10-07 15:29:36.114 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:29:36.115 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 846.24
2025-10-07 15:29:36.115 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:36.115 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:36.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:36.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:36.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:36.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:36.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:36.119 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:36.119 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:29:36.120 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.k_proj using 512 samples
2025-10-07 15:29:37.618 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:29:37.619 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 517.19
2025-10-07 15:29:37.620 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:37.620 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:37.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:37.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:37.622 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:37.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:37.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:37.624 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:37.625 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:29:37.625 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.v_proj using 512 samples
2025-10-07 15:29:39.157 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:29:39.158 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 46.97
2025-10-07 15:29:39.158 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:39.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:39.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:39.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:39.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:39.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:39.161 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:39.161 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:39.162 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:29:39.162 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.self_attn.o_proj using 512 samples
2025-10-07 15:29:40.743 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:29:40.744 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.15
2025-10-07 15:29:40.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:40.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:40.745 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:40.745 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:40.746 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:40.746 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:40.746 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:40.747 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:40.747 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:29:40.748 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.mlp.gate_proj using 512 samples
2025-10-07 15:29:42.350 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.60s
2025-10-07 15:29:42.350 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 976.80
2025-10-07 15:29:42.351 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:42.351 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:42.352 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:42.352 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:42.353 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:42.354 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:42.354 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:42.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:42.356 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:42.356 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.mlp.up_proj using 512 samples
2025-10-07 15:29:43.916 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:29:43.916 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 632.36
2025-10-07 15:29:43.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:43.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:43.921 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:43.922 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:43.922 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:43.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:43.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:43.924 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:43.925 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:43.925 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.8.mlp.down_proj using 512 samples
2025-10-07 15:29:49.749 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.82s
2025-10-07 15:29:49.750 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10.27
2025-10-07 15:29:49.751 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:29:49.751 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:49.752 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:49.753 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:49.753 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:49.754 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:49.754 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:49.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:49.756 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:29:49.756 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:29:56.260 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:29:56.260 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.q_proj using 512 samples
2025-10-07 15:29:57.781 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:29:57.782 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 833.19
2025-10-07 15:29:57.783 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:57.783 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:57.784 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:57.784 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:57.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:57.786 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:57.786 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:57.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:57.788 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:29:57.788 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.k_proj using 512 samples
2025-10-07 15:29:59.264 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:29:59.264 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 491.72
2025-10-07 15:29:59.265 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:29:59.265 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:59.266 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:29:59.266 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:29:59.266 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:29:59.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:59.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:59.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:29:59.268 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:29:59.268 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.v_proj using 512 samples
2025-10-07 15:30:00.747 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:30:00.748 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 65.16
2025-10-07 15:30:00.749 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:00.749 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:00.750 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:00.750 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:00.751 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:00.752 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:00.752 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:00.753 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:00.753 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:30:00.754 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.self_attn.o_proj using 512 samples
2025-10-07 15:30:02.293 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.54s
2025-10-07 15:30:02.293 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.61
2025-10-07 15:30:02.294 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:02.295 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:02.295 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:02.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:02.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:02.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:02.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:02.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:02.299 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:30:02.300 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.mlp.gate_proj using 512 samples
2025-10-07 15:30:03.849 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:30:03.849 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1045.27
2025-10-07 15:30:03.851 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:03.851 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:03.852 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:03.852 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:03.853 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:03.853 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:03.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:03.855 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:03.855 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:03.856 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.mlp.up_proj using 512 samples
2025-10-07 15:30:05.453 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.60s
2025-10-07 15:30:05.454 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 672.50
2025-10-07 15:30:05.455 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:05.455 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:05.456 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:05.456 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:05.457 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:05.458 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:05.458 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:05.459 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:05.460 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:05.460 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.9.mlp.down_proj using 512 samples
2025-10-07 15:30:11.193 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.73s
2025-10-07 15:30:11.195 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11.09
2025-10-07 15:30:11.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:30:11.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:11.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:11.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:11.198 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:11.198 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:11.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:11.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:11.200 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:11.201 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:30:17.697 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:30:17.697 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.q_proj using 512 samples
2025-10-07 15:30:19.175 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:30:19.176 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 990.99
2025-10-07 15:30:19.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:19.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:19.178 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:19.178 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:19.179 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:19.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:19.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:19.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:19.181 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:30:19.182 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.k_proj using 512 samples
2025-10-07 15:30:20.657 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:30:20.657 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 617.53
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:20.658 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:30:20.658 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.v_proj using 512 samples
2025-10-07 15:30:22.139 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:30:22.139 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 52.61
2025-10-07 15:30:22.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:22.141 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:22.141 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:22.142 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:22.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:22.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:22.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:22.145 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:22.145 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:30:22.146 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.self_attn.o_proj using 512 samples
2025-10-07 15:30:23.651 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:30:23.652 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.61
2025-10-07 15:30:23.653 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:23.653 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:23.654 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:23.654 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:23.655 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:23.656 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:23.656 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:23.657 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:23.657 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:30:23.658 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.mlp.gate_proj using 512 samples
2025-10-07 15:30:25.259 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.60s
2025-10-07 15:30:25.259 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1007.07
2025-10-07 15:30:25.263 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:25.264 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:25.265 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:25.265 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:25.266 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:25.266 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:25.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:25.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:25.268 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:25.269 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.mlp.up_proj using 512 samples
2025-10-07 15:30:26.829 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:30:26.830 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 693.50
2025-10-07 15:30:26.831 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:30:26.831 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:26.831 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:26.832 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:26.832 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:26.833 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:26.833 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:26.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:26.834 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:26.835 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.10.mlp.down_proj using 512 samples
2025-10-07 15:30:32.584 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.75s
2025-10-07 15:30:32.586 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11.54
2025-10-07 15:30:32.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:30:32.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:32.588 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:32.588 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:32.589 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:32.589 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:32.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:32.591 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:32.591 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:32.592 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:30:39.124 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:30:39.124 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.q_proj using 512 samples
2025-10-07 15:30:40.625 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:30:40.625 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 857.28
2025-10-07 15:30:40.626 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:30:40.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:40.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:40.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:40.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:40.629 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:40.629 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:40.630 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:40.630 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:30:40.631 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.k_proj using 512 samples
2025-10-07 15:30:42.092 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.46s
2025-10-07 15:30:42.093 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 548.80
2025-10-07 15:30:42.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:30:42.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:42.095 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:42.095 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:42.096 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:42.097 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:42.097 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:42.098 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:42.098 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:30:42.099 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.v_proj using 512 samples
2025-10-07 15:30:43.571 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:30:43.572 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 51.62
2025-10-07 15:30:43.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:30:43.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:43.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:43.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:43.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:43.576 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:43.576 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:43.577 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:43.577 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:30:43.578 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.self_attn.o_proj using 512 samples
2025-10-07 15:30:45.108 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:30:45.109 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.85
2025-10-07 15:30:45.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:30:45.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:45.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:45.111 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:45.111 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:45.112 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:45.112 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:45.113 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:45.113 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:30:45.114 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.mlp.gate_proj using 512 samples
2025-10-07 15:30:46.686 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:30:46.686 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1026.31
2025-10-07 15:30:46.687 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:30:46.687 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:46.688 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:46.688 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:46.689 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:46.690 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:46.690 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:46.691 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:46.691 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:46.692 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.mlp.up_proj using 512 samples
2025-10-07 15:30:48.253 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:30:48.253 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 727.49
2025-10-07 15:30:48.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:30:48.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:48.255 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:48.255 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:48.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:48.256 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:48.257 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:48.257 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:48.258 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:48.259 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.11.mlp.down_proj using 512 samples
2025-10-07 15:30:54.014 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.75s
2025-10-07 15:30:54.015 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 12.24
2025-10-07 15:30:54.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:30:54.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:54.017 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:30:54.018 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:30:54.018 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:30:54.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:54.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:54.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:30:54.021 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:30:54.021 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:31:00.585 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:31:00.585 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.q_proj using 512 samples
2025-10-07 15:31:02.101 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:31:02.101 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 752.88
2025-10-07 15:31:02.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:02.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:02.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:02.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:02.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:31:02.104 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:02.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:02.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:02.106 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:31:02.107 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.k_proj using 512 samples
2025-10-07 15:31:03.560 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.45s
2025-10-07 15:31:03.560 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 424.16
2025-10-07 15:31:03.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:03.561 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:03.561 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:03.561 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:03.561 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:31:03.562 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:03.563 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:03.563 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:03.564 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:31:03.565 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.v_proj using 512 samples
2025-10-07 15:31:05.097 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:31:05.098 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 60.88
2025-10-07 15:31:05.098 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:05.099 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:05.099 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:05.099 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:05.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:31:05.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:05.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:05.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:05.102 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:31:05.103 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.self_attn.o_proj using 512 samples
2025-10-07 15:31:06.611 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:31:06.612 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6.28
2025-10-07 15:31:06.612 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:06.613 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:06.613 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:06.613 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:06.614 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:31:06.614 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:06.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:06.616 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:06.616 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:31:06.617 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.mlp.gate_proj using 512 samples
2025-10-07 15:31:08.176 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:31:08.177 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 997.41
2025-10-07 15:31:08.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:08.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:08.178 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:08.178 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:08.179 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:31:08.179 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:08.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:08.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:08.181 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:08.182 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.mlp.up_proj using 512 samples
2025-10-07 15:31:09.743 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:31:09.743 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 742.60
2025-10-07 15:31:09.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:09.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:09.745 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:09.745 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:09.746 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.52% | total memory: 85 GB
2025-10-07 15:31:09.747 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:09.747 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:09.748 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:09.749 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:09.749 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.12.mlp.down_proj using 512 samples
2025-10-07 15:31:15.556 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.81s
2025-10-07 15:31:15.557 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13.13
2025-10-07 15:31:15.558 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:31:15.558 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:15.559 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:15.559 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:15.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:15.561 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:15.561 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:15.562 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:15.563 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:15.563 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:31:22.109 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:31:22.109 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.q_proj using 512 samples
2025-10-07 15:31:23.612 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:31:23.613 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 968.25
2025-10-07 15:31:23.613 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:23.614 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:23.614 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:23.614 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:23.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:23.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:23.616 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:23.617 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:23.617 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:31:23.618 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.k_proj using 512 samples
2025-10-07 15:31:25.085 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:31:25.086 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 630.84
2025-10-07 15:31:25.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:25.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:25.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:25.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:25.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:25.089 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:25.089 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:25.090 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:25.090 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:31:25.091 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.v_proj using 512 samples
2025-10-07 15:31:26.582 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:31:26.583 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 66.34
2025-10-07 15:31:26.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:26.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:26.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:26.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:26.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:26.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:26.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:26.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:26.587 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:31:26.587 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.self_attn.o_proj using 512 samples
2025-10-07 15:31:28.089 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:31:28.090 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6.62
2025-10-07 15:31:28.090 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:28.091 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:28.091 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:28.091 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:28.092 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:28.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:28.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:28.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:28.094 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:31:28.095 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.mlp.gate_proj using 512 samples
2025-10-07 15:31:29.660 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:31:29.660 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1051.16
2025-10-07 15:31:29.661 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:29.661 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:29.662 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:29.662 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:29.663 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:29.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:29.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:29.665 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:29.666 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:29.666 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.mlp.up_proj using 512 samples
2025-10-07 15:31:31.218 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:31:31.218 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 776.61
2025-10-07 15:31:31.219 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:31.219 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:31.219 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:31.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:31.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:31.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:31.221 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:31.221 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:31.222 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:31.223 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.13.mlp.down_proj using 512 samples
2025-10-07 15:31:37.022 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.80s
2025-10-07 15:31:37.023 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13.96
2025-10-07 15:31:37.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:31:37.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:37.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:37.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:37.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:37.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:37.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:37.025 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:37.025 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:37.025 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:31:43.461 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:31:43.461 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.q_proj using 512 samples
2025-10-07 15:31:45.037 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:31:45.038 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 954.57
2025-10-07 15:31:45.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:45.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:45.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:45.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:45.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:45.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:45.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:45.040 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:45.040 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:31:45.041 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.k_proj using 512 samples
2025-10-07 15:31:46.508 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:31:46.509 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 652.83
2025-10-07 15:31:46.509 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:46.510 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:31:46.511 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.v_proj using 512 samples
2025-10-07 15:31:48.064 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:31:48.064 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 66.74
2025-10-07 15:31:48.065 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:48.066 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:48.066 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:48.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:48.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:48.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:48.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:48.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:48.069 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:31:48.070 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.self_attn.o_proj using 512 samples
2025-10-07 15:31:49.585 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:31:49.586 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.37
2025-10-07 15:31:49.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:49.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:49.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 72.22% | total memory: 85 GB
2025-10-07 15:31:49.588 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:49.588 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:49.589 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:49.589 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:49.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:49.591 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:31:49.591 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.mlp.gate_proj using 512 samples
2025-10-07 15:31:51.156 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:31:51.157 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1169.00
2025-10-07 15:31:51.157 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:51.158 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:51.158 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:51.158 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:51.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:51.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:51.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:51.160 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:51.161 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:51.162 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.mlp.up_proj using 512 samples
2025-10-07 15:31:52.733 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:31:52.734 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 810.74
2025-10-07 15:31:52.734 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:31:52.734 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:52.735 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:52.736 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:52.736 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:52.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:52.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:52.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:52.739 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:52.740 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.14.mlp.down_proj using 512 samples
2025-10-07 15:31:58.571 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.83s
2025-10-07 15:31:58.572 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 15.93
2025-10-07 15:31:58.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:31:58.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:58.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:58.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:31:58.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:31:58.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:58.576 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:58.577 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:31:58.577 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:31:58.578 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:32:05.114 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:32:05.114 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.q_proj using 512 samples
2025-10-07 15:32:06.626 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:32:06.626 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1042.73
2025-10-07 15:32:06.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:06.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:06.629 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:06.629 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:06.630 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:06.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:06.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:06.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:06.632 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:32:06.633 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.k_proj using 512 samples
2025-10-07 15:32:08.098 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.46s
2025-10-07 15:32:08.098 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 545.09
2025-10-07 15:32:08.099 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:08.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:08.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:08.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:08.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:08.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:08.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:08.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:08.104 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:32:08.104 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.v_proj using 512 samples
2025-10-07 15:32:09.596 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:32:09.596 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 78.18
2025-10-07 15:32:09.597 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:09.598 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:09.598 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:09.599 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:09.599 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:09.600 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:09.600 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:09.601 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:09.601 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:32:09.602 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.self_attn.o_proj using 512 samples
2025-10-07 15:32:11.092 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:32:11.092 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.34
2025-10-07 15:32:11.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:11.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:11.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:11.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:11.095 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:11.095 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:11.096 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:11.096 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:11.097 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:32:11.098 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.mlp.gate_proj using 512 samples
2025-10-07 15:32:12.669 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:32:12.670 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1231.73
2025-10-07 15:32:12.670 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:12.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:12.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:12.672 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:12.673 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:12.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:12.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:12.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:12.674 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:12.674 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.mlp.up_proj using 512 samples
2025-10-07 15:32:14.244 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:32:14.244 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 813.63
2025-10-07 15:32:14.245 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:14.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:14.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:14.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:14.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:14.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:14.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:14.249 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:14.249 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:14.250 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.15.mlp.down_proj using 512 samples
2025-10-07 15:32:20.090 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.84s
2025-10-07 15:32:20.092 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 17.75
2025-10-07 15:32:20.092 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:32:20.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:20.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:20.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:20.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:20.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:20.095 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:20.095 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:20.096 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:20.097 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:32:26.638 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:32:26.638 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.q_proj using 512 samples
2025-10-07 15:32:28.172 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:32:28.172 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 877.87
2025-10-07 15:32:28.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:28.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:28.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.85% | total memory: 85 GB
2025-10-07 15:32:28.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:28.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:28.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:28.177 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:32:28.177 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.k_proj using 512 samples
2025-10-07 15:32:29.691 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:32:29.691 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 502.06
2025-10-07 15:32:29.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:29.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:29.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 1.57% | total memory: 85 GB
2025-10-07 15:32:29.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:29.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:29.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:29.695 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:29.695 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:29.696 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:32:29.696 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.v_proj using 512 samples
2025-10-07 15:32:31.191 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:32:31.191 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 64.27
2025-10-07 15:32:31.192 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:31.192 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:31.193 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 9.93% | total memory: 85 GB
2025-10-07 15:32:31.193 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:31.194 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:31.195 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:31.195 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:31.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:31.196 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:32:31.197 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.self_attn.o_proj using 512 samples
2025-10-07 15:32:32.707 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:32:32.707 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6.57
2025-10-07 15:32:32.708 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:32.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:32.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:32.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:32.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:32.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:32.712 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:32.713 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:32.713 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:32:32.714 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.mlp.gate_proj using 512 samples
2025-10-07 15:32:34.279 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:32:34.279 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1269.30
2025-10-07 15:32:34.280 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:34.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:34.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:34.282 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:34.283 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:34.283 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:34.284 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:34.284 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:34.285 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:34.286 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.mlp.up_proj using 512 samples
2025-10-07 15:32:35.894 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.61s
2025-10-07 15:32:35.895 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 800.63
2025-10-07 15:32:35.896 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:35.896 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:35.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:35.898 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:35.898 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:35.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:35.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:35.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:35.901 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:35.901 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.16.mlp.down_proj using 512 samples
2025-10-07 15:32:41.898 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 6.00s
2025-10-07 15:32:41.900 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 17.53
2025-10-07 15:32:41.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:32:41.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:41.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:41.903 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:41.903 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:41.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:41.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:41.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:41.905 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:41.906 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:32:48.468 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:32:48.468 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.q_proj using 512 samples
2025-10-07 15:32:49.994 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:32:49.995 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 886.63
2025-10-07 15:32:49.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:49.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:49.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:49.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:49.998 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:49.998 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:49.999 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:49.999 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:50.000 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:32:50.001 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.k_proj using 512 samples
2025-10-07 15:32:51.499 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:32:51.499 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 526.76
2025-10-07 15:32:51.500 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:51.501 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:51.501 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:51.502 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:51.502 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:51.503 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:51.503 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:51.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:51.505 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:32:51.505 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.v_proj using 512 samples
2025-10-07 15:32:52.997 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:32:52.997 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 69.67
2025-10-07 15:32:52.998 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:52.999 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:52.999 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:53.000 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:53.000 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:53.001 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:53.002 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:53.002 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:53.003 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:32:53.003 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.self_attn.o_proj using 512 samples
2025-10-07 15:32:54.531 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:32:54.531 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.83
2025-10-07 15:32:54.532 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:54.532 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:54.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:54.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:54.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:54.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:54.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:54.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:54.536 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:32:54.536 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.mlp.gate_proj using 512 samples
2025-10-07 15:32:56.175 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.64s
2025-10-07 15:32:56.175 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1308.06
2025-10-07 15:32:56.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:56.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:56.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:56.178 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:56.178 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:56.179 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:56.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:56.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:56.181 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:56.181 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.mlp.up_proj using 512 samples
2025-10-07 15:32:57.765 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:32:57.765 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 806.26
2025-10-07 15:32:57.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:32:57.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:57.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 12.66% | total memory: 85 GB
2025-10-07 15:32:57.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:32:57.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:32:57.769 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:57.769 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:57.770 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:32:57.771 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:32:57.771 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.17.mlp.down_proj using 512 samples
2025-10-07 15:33:03.551 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.78s
2025-10-07 15:33:03.553 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 19.47
2025-10-07 15:33:03.554 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:33:03.554 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:03.555 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 13.08% | total memory: 85 GB
2025-10-07 15:33:03.555 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:03.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:03.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:03.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:03.558 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:03.558 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:33:03.559 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:33:10.013 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:33:10.013 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.q_proj using 512 samples
2025-10-07 15:33:11.534 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:33:11.534 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 864.94
2025-10-07 15:33:11.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:11.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:11.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:11.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:11.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:11.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:11.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:11.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:11.540 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:33:11.541 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.k_proj using 512 samples
2025-10-07 15:33:13.033 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:33:13.034 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 557.09
2025-10-07 15:33:13.034 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:13.034 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:13.035 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:13.036 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:13.036 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:13.037 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:13.037 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:13.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:13.039 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:33:13.039 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.v_proj using 512 samples
2025-10-07 15:33:14.532 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:33:14.532 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 67.90
2025-10-07 15:33:14.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:14.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:14.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:14.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:14.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:14.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:14.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:14.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:14.537 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:33:14.538 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.self_attn.o_proj using 512 samples
2025-10-07 15:33:16.099 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:33:16.100 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.09
2025-10-07 15:33:16.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:16.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:16.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:16.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:16.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:16.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:16.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:16.104 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:16.105 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:33:16.105 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.mlp.gate_proj using 512 samples
2025-10-07 15:33:17.699 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.59s
2025-10-07 15:33:17.700 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1296.81
2025-10-07 15:33:17.700 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:17.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:17.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:17.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:17.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:17.702 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:17.702 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:17.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:17.703 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:33:17.704 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.mlp.up_proj using 512 samples
2025-10-07 15:33:19.291 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.59s
2025-10-07 15:33:19.292 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 795.21
2025-10-07 15:33:19.292 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:19.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:19.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:19.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:19.294 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:19.295 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:19.295 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:19.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:19.296 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:33:19.297 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.18.mlp.down_proj using 512 samples
2025-10-07 15:33:25.105 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.81s
2025-10-07 15:33:25.106 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 17.96
2025-10-07 15:33:25.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:33:25.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:25.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:25.109 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:25.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:25.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:25.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:25.111 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:25.112 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:33:25.112 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:33:31.656 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:33:31.657 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.q_proj using 512 samples
2025-10-07 15:33:33.184 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:33:33.185 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 848.12
2025-10-07 15:33:33.186 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:33.186 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:33.187 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:33.187 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:33.188 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:33.189 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:33.189 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:33.190 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:33.191 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:33:33.191 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.k_proj using 512 samples
2025-10-07 15:33:34.682 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:33:34.682 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 491.60
2025-10-07 15:33:34.683 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:34.684 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:34.684 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:34.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:34.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:34.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:34.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:34.687 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:34.687 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:33:34.688 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.v_proj using 512 samples
2025-10-07 15:33:36.246 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:33:36.247 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 69.29
2025-10-07 15:33:36.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:36.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:36.249 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:36.249 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:36.250 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:36.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:36.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:36.252 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:36.252 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:33:36.253 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.self_attn.o_proj using 512 samples
2025-10-07 15:33:37.765 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:33:37.765 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.07
2025-10-07 15:33:37.765 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:37.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:37.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:37.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:37.769 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:37.770 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:37.770 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:33:37.771 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.mlp.gate_proj using 512 samples
2025-10-07 15:33:39.394 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.62s
2025-10-07 15:33:39.395 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1335.41
2025-10-07 15:33:39.395 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:39.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:39.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:39.397 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:39.398 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:39.398 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:39.399 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:39.399 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:39.400 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:33:39.401 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.mlp.up_proj using 512 samples
2025-10-07 15:33:40.974 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:33:40.975 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 803.94
2025-10-07 15:33:40.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:40.976 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:40.976 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:40.977 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:40.977 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:40.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:40.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:40.979 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:40.979 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:33:40.980 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.19.mlp.down_proj using 512 samples
2025-10-07 15:33:47.154 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 6.17s
2025-10-07 15:33:47.155 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 18.44
2025-10-07 15:33:47.157 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:33:47.157 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:47.157 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:47.157 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:47.157 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:47.158 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:47.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:47.159 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:47.160 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:33:47.161 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:33:53.701 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:33:53.701 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.q_proj using 512 samples
2025-10-07 15:33:55.246 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.54s
2025-10-07 15:33:55.247 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 872.17
2025-10-07 15:33:55.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:55.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:55.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:55.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:55.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:55.249 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:55.249 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:55.249 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:55.250 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:33:55.251 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.k_proj using 512 samples
2025-10-07 15:33:56.743 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:33:56.744 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 541.27
2025-10-07 15:33:56.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:56.745 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:56.745 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:56.745 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:56.746 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:56.746 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:56.747 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:56.747 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:56.748 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:33:56.748 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.v_proj using 512 samples
2025-10-07 15:33:58.248 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:33:58.249 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 78.44
2025-10-07 15:33:58.249 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:58.250 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:58.250 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:58.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:58.252 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:58.252 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:58.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:58.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:58.254 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:33:58.255 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.self_attn.o_proj using 512 samples
2025-10-07 15:33:59.753 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:33:59.754 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.61
2025-10-07 15:33:59.754 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:33:59.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:59.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:33:59.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:33:59.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:33:59.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:59.757 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:59.758 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:33:59.758 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:33:59.759 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.mlp.gate_proj using 512 samples
2025-10-07 15:34:01.343 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:34:01.343 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1403.79
2025-10-07 15:34:01.344 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:01.344 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:01.345 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:01.345 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:01.346 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:01.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:01.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:01.348 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:01.349 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:01.349 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.mlp.up_proj using 512 samples
2025-10-07 15:34:02.898 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:34:02.899 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 854.04
2025-10-07 15:34:02.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:02.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:02.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:02.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:02.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:02.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:02.903 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:02.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:02.904 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:02.905 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.20.mlp.down_proj using 512 samples
2025-10-07 15:34:08.776 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.87s
2025-10-07 15:34:08.777 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 19.51
2025-10-07 15:34:08.778 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:34:08.778 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:08.779 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:08.779 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:08.780 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:08.781 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:08.781 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:08.782 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:08.783 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:08.783 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:34:15.323 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:34:15.323 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.q_proj using 512 samples
2025-10-07 15:34:16.834 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:34:16.834 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 817.55
2025-10-07 15:34:16.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:16.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:16.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:16.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:16.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:16.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:16.839 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:16.839 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:16.840 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:34:16.841 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.k_proj using 512 samples
2025-10-07 15:34:18.381 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.54s
2025-10-07 15:34:18.382 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 497.83
2025-10-07 15:34:18.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:18.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:18.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:18.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:18.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:18.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:18.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:18.387 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:18.387 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:34:18.388 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.v_proj using 512 samples
2025-10-07 15:34:19.870 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:34:19.870 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 81.33
2025-10-07 15:34:19.870 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:19.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:19.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:19.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:19.873 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:19.873 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:19.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:19.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:19.875 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:34:19.876 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.self_attn.o_proj using 512 samples
2025-10-07 15:34:21.358 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:34:21.358 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.64
2025-10-07 15:34:21.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:21.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:21.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:21.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:21.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:21.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:21.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:21.362 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:21.363 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:34:21.363 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.mlp.gate_proj using 512 samples
2025-10-07 15:34:22.926 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:34:22.926 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1516.05
2025-10-07 15:34:22.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:22.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:22.928 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:22.928 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:22.929 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:22.930 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:22.930 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:22.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:22.932 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:22.932 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.mlp.up_proj using 512 samples
2025-10-07 15:34:24.498 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:34:24.498 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 913.27
2025-10-07 15:34:24.499 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:24.499 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:24.499 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:24.500 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:24.500 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:24.501 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:24.501 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:24.502 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:24.503 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:24.503 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.21.mlp.down_proj using 512 samples
2025-10-07 15:34:30.295 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.79s
2025-10-07 15:34:30.296 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 23.36
2025-10-07 15:34:30.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:34:30.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:30.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:30.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:30.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:30.300 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:30.300 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:30.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:30.302 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:30.302 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:34:36.889 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:34:36.890 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.q_proj using 512 samples
2025-10-07 15:34:38.407 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:34:38.407 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 838.63
2025-10-07 15:34:38.408 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:38.408 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:38.409 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:38.409 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:38.410 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:38.411 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:38.411 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:38.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:38.413 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:34:38.413 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.k_proj using 512 samples
2025-10-07 15:34:39.871 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.46s
2025-10-07 15:34:39.871 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 536.64
2025-10-07 15:34:39.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:39.873 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:39.873 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:39.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:39.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:39.875 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:39.876 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:39.876 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:39.877 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:34:39.878 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.v_proj using 512 samples
2025-10-07 15:34:41.365 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:34:41.366 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 95.47
2025-10-07 15:34:41.366 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:41.367 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:41.367 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:41.368 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:41.368 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:41.369 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:41.370 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:41.370 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:41.371 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:34:41.371 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.self_attn.o_proj using 512 samples
2025-10-07 15:34:42.850 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:34:42.851 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3.61
2025-10-07 15:34:42.851 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:42.852 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:42.852 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:42.853 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:42.853 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:42.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:42.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:42.855 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:42.856 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:34:42.856 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.mlp.gate_proj using 512 samples
2025-10-07 15:34:44.433 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.58s
2025-10-07 15:34:44.433 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1563.78
2025-10-07 15:34:44.433 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:44.434 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:44.434 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:44.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:44.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:44.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:44.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:44.437 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:44.438 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:44.438 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.mlp.up_proj using 512 samples
2025-10-07 15:34:46.097 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.66s
2025-10-07 15:34:46.098 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 954.29
2025-10-07 15:34:46.098 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:34:46.098 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:46.099 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:46.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:46.100 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:46.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:46.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:46.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:46.103 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:46.103 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.22.mlp.down_proj using 512 samples
2025-10-07 15:34:51.902 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.80s
2025-10-07 15:34:51.903 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 25.08
2025-10-07 15:34:51.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:34:51.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:51.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:34:51.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:34:51.904 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:34:51.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:51.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:51.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:34:51.905 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:34:51.906 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:34:58.453 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:34:58.453 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.q_proj using 512 samples
2025-10-07 15:35:00.009 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:35:00.009 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 890.53
2025-10-07 15:35:00.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:00.011 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:00.011 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:00.011 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:00.012 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:00.012 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:00.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:00.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:00.014 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:35:00.014 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.k_proj using 512 samples
2025-10-07 15:35:01.507 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:35:01.507 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 558.83
2025-10-07 15:35:01.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:01.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:01.509 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:01.509 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:01.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:01.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:01.511 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:01.512 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:01.512 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:35:01.513 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.v_proj using 512 samples
2025-10-07 15:35:02.990 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:35:02.990 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 106.57
2025-10-07 15:35:02.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:02.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:02.992 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:02.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:02.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:02.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:02.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:02.995 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:02.996 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:35:02.996 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.self_attn.o_proj using 512 samples
2025-10-07 15:35:04.526 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:35:04.527 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.77
2025-10-07 15:35:04.527 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:04.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:04.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:04.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:04.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:04.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:04.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:04.531 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:04.532 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:35:04.532 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.mlp.gate_proj using 512 samples
2025-10-07 15:35:06.145 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.61s
2025-10-07 15:35:06.146 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1673.68
2025-10-07 15:35:06.147 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:06.147 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:06.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:06.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:06.149 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:06.150 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:06.150 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:06.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:06.151 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:06.152 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.mlp.up_proj using 512 samples
2025-10-07 15:35:07.727 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:35:07.727 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1027.75
2025-10-07 15:35:07.728 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:07.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:07.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:07.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:07.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:07.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:07.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:07.732 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:07.733 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:07.733 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.23.mlp.down_proj using 512 samples
2025-10-07 15:35:13.621 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.89s
2025-10-07 15:35:13.622 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 29.25
2025-10-07 15:35:13.623 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:35:13.624 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:13.624 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:13.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:13.626 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:13.626 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:13.626 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:13.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:13.628 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:13.628 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:35:20.251 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:35:20.251 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.q_proj using 512 samples
2025-10-07 15:35:21.777 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:35:21.778 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 891.58
2025-10-07 15:35:21.778 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:21.779 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:21.779 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:21.779 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:21.780 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:21.780 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:21.781 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:21.782 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:21.782 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:35:21.783 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.k_proj using 512 samples
2025-10-07 15:35:23.283 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:35:23.283 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 544.21
2025-10-07 15:35:23.284 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:23.285 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:23.285 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:23.285 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:23.286 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:23.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:23.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:23.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:23.288 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:35:23.289 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.v_proj using 512 samples
2025-10-07 15:35:24.805 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:35:24.805 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 136.81
2025-10-07 15:35:24.806 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:24.806 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:24.807 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:24.807 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:24.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:24.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:24.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:24.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:24.809 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:35:24.810 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.self_attn.o_proj using 512 samples
2025-10-07 15:35:26.376 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:35:26.377 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.88
2025-10-07 15:35:26.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:26.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:26.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:26.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:26.380 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:26.380 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:26.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:26.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:26.382 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:35:26.382 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.mlp.gate_proj using 512 samples
2025-10-07 15:35:27.935 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:35:27.936 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1774.42
2025-10-07 15:35:27.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:27.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:27.938 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:27.938 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:27.939 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:27.940 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:27.940 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:27.941 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:27.941 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:27.942 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.mlp.up_proj using 512 samples
2025-10-07 15:35:29.508 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:35:29.509 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1088.67
2025-10-07 15:35:29.509 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:29.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:29.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:29.510 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:29.511 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 75.53% | total memory: 85 GB
2025-10-07 15:35:29.511 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:29.512 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:29.513 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:29.513 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:29.514 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.24.mlp.down_proj using 512 samples
2025-10-07 15:35:35.380 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.87s
2025-10-07 15:35:35.381 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 33.56
2025-10-07 15:35:35.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:35:35.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:35.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:35.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:35.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:35.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:35.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:35.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:35.386 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:35.386 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:35:42.009 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:35:42.010 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.q_proj using 512 samples
2025-10-07 15:35:43.540 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:35:43.540 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 889.30
2025-10-07 15:35:43.540 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:43.541 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:43.541 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:43.541 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:43.542 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:43.542 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:43.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:43.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:43.544 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:35:43.544 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.k_proj using 512 samples
2025-10-07 15:35:45.067 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:35:45.068 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 520.86
2025-10-07 15:35:45.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:45.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:45.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:45.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:45.069 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:45.070 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:45.070 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:45.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:45.071 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:35:45.071 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.v_proj using 512 samples
2025-10-07 15:35:46.576 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:35:46.577 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 140.69
2025-10-07 15:35:46.578 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:46.578 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:46.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:46.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:46.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:46.581 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:46.581 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:46.582 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:46.582 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:35:46.583 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.self_attn.o_proj using 512 samples
2025-10-07 15:35:48.089 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:35:48.089 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.67
2025-10-07 15:35:48.090 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:48.090 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:48.091 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:48.091 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:48.092 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:48.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:48.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:48.094 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:48.095 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:35:48.095 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.mlp.gate_proj using 512 samples
2025-10-07 15:35:49.645 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:35:49.646 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1937.14
2025-10-07 15:35:49.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:49.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:49.648 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:49.649 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:49.649 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:49.650 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:49.650 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:49.650 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:49.651 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:49.652 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.mlp.up_proj using 512 samples
2025-10-07 15:35:51.214 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:35:51.215 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1189.94
2025-10-07 15:35:51.215 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:35:51.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:51.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:51.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:51.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:51.218 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:51.219 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:51.219 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:51.220 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:51.220 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.25.mlp.down_proj using 512 samples
2025-10-07 15:35:57.105 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.88s
2025-10-07 15:35:57.107 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 42.29
2025-10-07 15:35:57.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:35:57.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:57.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:35:57.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:35:57.108 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:35:57.109 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:57.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:57.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:35:57.111 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:35:57.112 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:36:03.732 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:36:03.732 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.q_proj using 512 samples
2025-10-07 15:36:05.258 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:36:05.259 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 848.82
2025-10-07 15:36:05.259 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:36:05.259 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:05.260 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:05.260 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:05.261 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:05.262 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:05.262 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:05.263 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:05.263 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:36:05.264 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.k_proj using 512 samples
2025-10-07 15:36:06.755 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:36:06.756 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 544.54
2025-10-07 15:36:06.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:36:06.757 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:06.757 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:06.758 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:06.758 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:06.759 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:06.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:06.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:06.761 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:36:06.762 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.v_proj using 512 samples
2025-10-07 15:36:08.237 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:36:08.237 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 136.58
2025-10-07 15:36:08.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:36:08.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:08.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:08.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:08.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:08.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:08.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:08.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:08.241 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:36:08.241 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.self_attn.o_proj using 512 samples
2025-10-07 15:36:09.757 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:36:09.758 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8.58
2025-10-07 15:36:09.758 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:36:09.759 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:09.759 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:09.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:09.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:09.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:09.762 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:09.762 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:09.763 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:36:09.764 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.mlp.gate_proj using 512 samples
2025-10-07 15:36:11.314 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.55s
2025-10-07 15:36:11.315 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2102.85
2025-10-07 15:36:11.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:36:11.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:11.317 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:11.317 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:11.318 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:11.319 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:11.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:11.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:11.321 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:11.322 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.mlp.up_proj using 512 samples
2025-10-07 15:36:12.894 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:36:12.895 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1285.86
2025-10-07 15:36:12.895 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:36:12.895 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:12.896 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:12.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:12.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:12.898 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:12.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:12.899 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:12.900 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:12.900 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.26.mlp.down_proj using 512 samples
2025-10-07 15:36:18.758 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.86s
2025-10-07 15:36:18.759 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 54.37
2025-10-07 15:36:18.759 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:36:18.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:18.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:18.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:18.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:18.762 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:18.762 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:18.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:18.764 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:18.764 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:36:25.286 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:36:25.286 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.q_proj using 512 samples
2025-10-07 15:36:26.814 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:36:26.815 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 912.88
2025-10-07 15:36:26.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:26.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:26.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:26.817 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:26.817 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:26.818 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:26.818 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:26.819 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:26.819 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:36:26.820 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.k_proj using 512 samples
2025-10-07 15:36:28.296 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:36:28.296 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 605.96
2025-10-07 15:36:28.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:28.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:28.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:28.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:28.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:28.300 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:28.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:28.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:28.302 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:36:28.302 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.v_proj using 512 samples
2025-10-07 15:36:29.799 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.50s
2025-10-07 15:36:29.799 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 193.48
2025-10-07 15:36:29.800 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:29.800 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:29.800 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:29.801 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:29.801 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:29.802 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:29.802 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:29.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:29.804 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:36:29.804 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.self_attn.o_proj using 512 samples
2025-10-07 15:36:31.313 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:36:31.314 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6.55
2025-10-07 15:36:31.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:31.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:31.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:31.317 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:31.317 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:31.318 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:31.318 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:31.319 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:31.319 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:36:31.320 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.mlp.gate_proj using 512 samples
2025-10-07 15:36:32.888 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:36:32.889 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2337.36
2025-10-07 15:36:32.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:32.890 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:32.890 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:32.890 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:32.891 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:32.891 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:32.892 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:32.892 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:32.893 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:32.894 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.mlp.up_proj using 512 samples
2025-10-07 15:36:34.466 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:36:34.467 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1443.63
2025-10-07 15:36:34.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:34.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:34.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:34.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:34.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:34.470 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:34.471 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:34.471 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:34.472 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:34.473 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.27.mlp.down_proj using 512 samples
2025-10-07 15:36:40.308 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.84s
2025-10-07 15:36:40.310 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 71.53
2025-10-07 15:36:40.310 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:36:40.311 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:40.311 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:40.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:40.313 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:40.313 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:40.314 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:40.314 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:40.315 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:40.316 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:36:46.912 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:36:46.913 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.q_proj using 512 samples
2025-10-07 15:36:48.424 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:36:48.425 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 843.47
2025-10-07 15:36:48.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:48.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:48.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:48.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:48.427 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:48.427 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:48.428 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:48.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:48.429 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:36:48.430 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.k_proj using 512 samples
2025-10-07 15:36:49.885 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.45s
2025-10-07 15:36:49.886 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 494.48
2025-10-07 15:36:49.886 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:49.887 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:49.887 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:49.888 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:49.888 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:49.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:49.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:49.890 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:49.891 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:36:49.891 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.v_proj using 512 samples
2025-10-07 15:36:51.372 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:36:51.372 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 178.22
2025-10-07 15:36:51.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:51.373 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:51.374 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:51.374 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:51.375 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:51.375 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:51.376 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:51.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:51.377 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:36:51.378 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.self_attn.o_proj using 512 samples
2025-10-07 15:36:52.864 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.49s
2025-10-07 15:36:52.865 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 14.85
2025-10-07 15:36:52.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:52.866 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:52.866 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:52.866 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:52.867 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:52.868 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:52.868 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:52.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:52.869 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:36:52.870 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.mlp.gate_proj using 512 samples
2025-10-07 15:36:54.427 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:36:54.427 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2479.92
2025-10-07 15:36:54.428 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:54.428 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:54.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:54.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:54.430 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:54.431 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:54.431 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:54.432 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:54.433 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:54.433 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.mlp.up_proj using 512 samples
2025-10-07 15:36:56.050 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.62s
2025-10-07 15:36:56.051 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1598.23
2025-10-07 15:36:56.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:36:56.052 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:56.052 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:36:56.052 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:36:56.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:36:56.054 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:56.054 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:56.055 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:36:56.056 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:36:56.056 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.28.mlp.down_proj using 512 samples
2025-10-07 15:37:01.802 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.75s
2025-10-07 15:37:01.803 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 96.10
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 78.57% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:01.804 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:01.805 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:37:08.417 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:37:08.418 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.q_proj using 512 samples
2025-10-07 15:37:09.946 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:37:09.947 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 947.38
2025-10-07 15:37:09.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:37:09.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:09.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:09.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:09.949 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:09.950 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:09.950 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:09.951 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:09.952 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:37:09.952 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.k_proj using 512 samples
2025-10-07 15:37:11.422 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:37:11.423 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 543.84
2025-10-07 15:37:11.423 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:37:11.424 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:11.424 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:11.424 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:11.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:11.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:11.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:11.427 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:11.427 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:37:11.428 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.v_proj using 512 samples
2025-10-07 15:37:12.913 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.48s
2025-10-07 15:37:12.913 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 215.06
2025-10-07 15:37:12.913 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:37:12.914 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:12.914 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:12.914 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:12.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:12.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:12.916 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:12.916 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:12.917 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:37:12.917 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.self_attn.o_proj using 512 samples
2025-10-07 15:37:14.424 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:37:14.424 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 18.12
2025-10-07 15:37:14.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:37:14.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:14.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:14.426 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:14.427 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:14.428 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:14.428 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:14.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:14.430 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:37:14.430 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.mlp.gate_proj using 512 samples
2025-10-07 15:37:16.019 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.59s
2025-10-07 15:37:16.020 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2581.05
2025-10-07 15:37:16.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:37:16.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:16.022 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:16.023 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:16.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:16.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:16.025 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:16.025 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:16.026 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:16.027 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.mlp.up_proj using 512 samples
2025-10-07 15:37:17.599 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.57s
2025-10-07 15:37:17.599 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1734.99
2025-10-07 15:37:17.600 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.94% | total memory: 85 GB
2025-10-07 15:37:17.600 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:17.601 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:17.601 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:17.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:17.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:17.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:17.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:17.605 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:17.605 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.29.mlp.down_proj using 512 samples
2025-10-07 15:37:23.404 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.80s
2025-10-07 15:37:23.406 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 134.73
2025-10-07 15:37:23.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:37:23.407 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:23.407 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:23.407 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:23.407 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:23.408 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:23.408 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:23.409 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:23.410 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:23.411 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:37:30.027 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:37:30.027 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.30.self_attn.q_proj using 512 samples
2025-10-07 15:37:31.548 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.52s
2025-10-07 15:37:31.548 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 834.40
2025-10-07 15:37:31.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:31.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:31.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:31.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:31.551 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:31.552 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:31.552 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:31.553 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:31.554 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:37:31.554 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.30.self_attn.k_proj using 512 samples
2025-10-07 15:37:33.060 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:37:33.061 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 543.67
2025-10-07 15:37:33.062 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:33.062 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:33.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:33.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:33.064 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:33.064 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:33.065 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:33.066 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:33.066 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:37:33.067 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.30.self_attn.v_proj using 512 samples
2025-10-07 15:37:34.576 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.51s
2025-10-07 15:37:34.576 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 297.17
2025-10-07 15:37:34.577 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:34.577 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:34.578 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:34.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:34.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:34.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:34.581 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:34.581 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:34.582 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:37:34.582 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.30.self_attn.o_proj using 512 samples
2025-10-07 15:37:36.213 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.63s
2025-10-07 15:37:36.213 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 23.94
2025-10-07 15:37:36.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:36.215 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:36.215 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:36.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:36.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:36.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:36.218 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:36.218 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:36.219 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:37:36.220 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.30.mlp.gate_proj using 512 samples
2025-10-07 15:37:37.862 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.64s
2025-10-07 15:37:37.863 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2833.43
2025-10-07 15:37:37.863 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:37.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:37.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:37.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:37.866 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:37.866 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:37.867 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:37.868 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:37.868 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:37.869 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.30.mlp.up_proj using 512 samples
2025-10-07 15:37:39.525 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.66s
2025-10-07 15:37:39.526 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1869.11
2025-10-07 15:37:39.526 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:39.526 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:39.527 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:39.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:39.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:39.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:39.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:39.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:39.531 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:39.531 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.30.mlp.down_proj using 512 samples
2025-10-07 15:37:45.396 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.86s
2025-10-07 15:37:45.398 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 208.37
2025-10-07 15:37:45.399 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:37:45.399 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:45.399 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:45.400 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:45.400 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:45.401 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:45.401 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:45.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:45.402 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:45.403 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:37:51.996 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:37:51.996 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.31.self_attn.q_proj using 512 samples
2025-10-07 15:37:53.536 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.54s
2025-10-07 15:37:53.537 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 679.51
2025-10-07 15:37:53.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:53.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:53.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:53.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:53.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:53.539 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:53.540 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:53.540 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:53.541 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:37:53.541 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.31.self_attn.k_proj using 512 samples
2025-10-07 15:37:55.011 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.47s
2025-10-07 15:37:55.012 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 372.70
2025-10-07 15:37:55.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:55.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:55.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:55.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:55.014 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:55.014 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:55.015 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:55.015 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:55.016 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:37:55.016 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.31.self_attn.v_proj using 512 samples
2025-10-07 15:37:56.544 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.53s
2025-10-07 15:37:56.545 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 162.65
2025-10-07 15:37:56.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:56.546 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:56.546 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:56.547 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:56.547 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:56.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:56.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:56.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:56.549 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.486912 MB
2025-10-07 15:37:56.551 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.31.self_attn.o_proj using 512 samples
2025-10-07 15:37:58.108 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.56s
2025-10-07 15:37:58.109 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 37.81
2025-10-07 15:37:58.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:58.110 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:58.111 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:58.111 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:58.112 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:58.112 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:58.113 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:58.114 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:58.114 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 33.947648 MB
2025-10-07 15:37:58.115 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.31.mlp.gate_proj using 512 samples
2025-10-07 15:37:59.802 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.69s
2025-10-07 15:37:59.803 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2479.91
2025-10-07 15:37:59.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:37:59.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:59.805 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:37:59.806 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:37:59.806 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:37:59.807 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:59.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:59.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:37:59.808 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:37:59.809 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.31.mlp.up_proj using 512 samples
2025-10-07 15:38:01.477 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.67s
2025-10-07 15:38:01.477 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1719.20
2025-10-07 15:38:01.477 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.95% | total memory: 85 GB
2025-10-07 15:38:01.478 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:01.478 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:38:01.479 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:38:01.480 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:38:01.480 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:01.481 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:01.481 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:01.482 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:38:01.483 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:251 - Quantizing model.layers.31.mlp.down_proj using 512 samples
2025-10-07 15:38:07.496 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 6.01s
2025-10-07 15:38:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 623.16
2025-10-07 15:38:07.498 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.86% | total memory: 85 GB
2025-10-07 15:38:07.499 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:07.499 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 49.75% | total memory: 85 GB
2025-10-07 15:38:07.500 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 37.93% | total memory: 85 GB
2025-10-07 15:38:07.501 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 81.78% | total memory: 85 GB
2025-10-07 15:38:07.501 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:07.502 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:07.502 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.84% | total memory: 85 GB
2025-10-07 15:38:07.503 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 118.816768 MB
2025-10-07 15:38:07.504 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:38:09.386 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-07 15:38:09.386 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:38:10.362 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2025-10-07 15:38:10.368 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:38:10.371 | DEBUG    | llmcompressor.core.lifecycle:finalize:134 - Finalizing compression lifecycle
2025-10-07 15:38:10.371 | DEBUG    | llmcompressor.core.lifecycle:finalize:138 - Finalized modifier: config_groups={'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=4, type='int', symmetric=True, group_size=128, strategy='group', block_structure=None, dynamic=False, actorder=<ActivationOrdering.STATIC: 'static'>, observer='minmax', observer_kwargs={}), input_activations=None, output_activations=None, format=None)} targets=['Linear'] ignore=['lm_head'] scheme=None kv_cache_scheme=None index=None group='quant' start=None end=None update=None initialized_=True finalized_=True started_=True ended_=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-07 15:38:10.372 | INFO     | llmcompressor.core.lifecycle:finalize:144 - Compression lifecycle finalized for 1 modifiers
2025-10-07 15:38:10.415 | INFO     | llmcompressor.transformers.compression.compressed_tensors_utils:get_model_compressor:193 - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.
2025-10-07 15:39:17.611 | DEBUG    | llmcompressor.transformers.utils.helpers:infer_recipe_from_model_path:105 - No recipe found in the model_path: /proiektuak/ikergaitu-data/azabala106/model_evaluation/trained_models/Latxa3.1_8b_lr1e-5
