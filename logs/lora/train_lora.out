hyperparameters
modelo cargado
tokenizer cargado
dataset cargado
{'loss': 1.0294, 'grad_norm': 1.0650619268417358, 'learning_rate': 0.00044450364783998685, 'epoch': 1.0}
{'eval_loss': 0.954535722732544, 'eval_runtime': 471.9656, 'eval_samples_per_second': 22.968, 'eval_steps_per_second': 5.742, 'epoch': 1.0}
{'loss': 0.8868, 'grad_norm': 1.4034218788146973, 'learning_rate': 0.00033338798262152634, 'epoch': 2.0}
{'eval_loss': 0.9152471423149109, 'eval_runtime': 611.7542, 'eval_samples_per_second': 17.72, 'eval_steps_per_second': 4.43, 'epoch': 2.0}
{'loss': 0.7816, 'grad_norm': 1.9811738729476929, 'learning_rate': 0.00022227231740306583, 'epoch': 3.0}
{'eval_loss': 0.9058047533035278, 'eval_runtime': 467.9988, 'eval_samples_per_second': 23.162, 'eval_steps_per_second': 5.791, 'epoch': 3.0}
{'loss': 0.6757, 'grad_norm': 1.5439397096633911, 'learning_rate': 0.0001111566521846053, 'epoch': 4.0}
{'eval_loss': 0.9201393723487854, 'eval_runtime': 467.5229, 'eval_samples_per_second': 23.186, 'eval_steps_per_second': 5.797, 'epoch': 4.0}
{'loss': 0.5695, 'grad_norm': 1.439475178718567, 'learning_rate': 4.098696614476597e-08, 'epoch': 5.0}
{'eval_loss': 0.9619057774543762, 'eval_runtime': 473.9324, 'eval_samples_per_second': 22.872, 'eval_steps_per_second': 5.718, 'epoch': 5.0}
{'train_runtime': 59927.3546, 'train_samples_per_second': 7.236, 'train_steps_per_second': 0.226, 'train_loss': 0.7885969667846274, 'epoch': 5.0}
entrenado
Eval results: {'eval_loss': 0.9058047533035278, 'eval_runtime': 482.8286, 'eval_samples_per_second': 22.451, 'eval_steps_per_second': 5.613, 'epoch': 5.0}
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mlatxa8b_instruct[0m at: [34mhttps://wandb.ai/maytemuma-upv-ehu/lora-latxa8b/runs/ov4ellca[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250609_082142-ov4ellca/logs[0m
